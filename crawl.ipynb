{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<p style = \"text-align: center\">TR∆Ø·ªúNG ƒê·∫†I H·ªåC KHOA H·ªåC T·ª∞ NHI√äN - ƒê·∫†I H·ªåC QU·ªêC GIA TPHCM</p>**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<p style = \"text-align: center\">NH·∫¨P M√îN KHOA H·ªåC D·ªÆ LI·ªÜU</p>**\n",
    "## **<p style = \"text-align: center\">ƒê·ªì √°n Cu·ªëi k√¨</p>**\n",
    "### <p style = \"text-align: center\"> <b>ƒê·ªÅ t√†i:</b> Ph√¢n t√≠ch, kh√°m ph√° d·ªØ li·ªáu v·ªÅ s√°ch tr√™n web th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ (tiki)</p>\n",
    "## **<p style = \"text-align: center\">THU TH·∫¨P D·ªÆ LI·ªÜU</p>**\n",
    "**Sinh vi√™n th·ª±c hi·ªán**\n",
    "\n",
    "| M√£ s·ªë sinh vi√™n | H·ªç v√† t√™n |\n",
    "| --- | --- |\n",
    "| 20120040 | Nguy·ªÖn Quang Gia B·∫£o |\n",
    "| 20120136 | Hu·ª≥nh Tu·∫•n Nam |\n",
    "| 20120158 | Tr·∫ßn Ho√†ng Anh Phi |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Install c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# import requests\n",
    "import json\n",
    "import httpx\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D√πng scrapy\n",
    "-> G·∫∑p l·ªói 403 forbidden v√† kh√¥ng get ƒë∆∞·ª£c d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Selenium c≈©ng t∆∞∆°ng t·ª±, javascript ch·ªâ load sau khi ƒë√£ raise exception timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Crawl tiki**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L·∫•y danh m·ª•c s·∫£n ph·∫©m trong danh m·ª•c s√°ch ti·∫øng Vi·ªát ·ªü api c·ªßa tiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_url(category, page, urlKey):\n",
    "    return f'https://tiki.vn/api/personalish/v1/blocks/listings?limit=100&aggregations=2&sort=top_seller&category={category}&page={page}&urlKey={urlKey}'\n",
    "\n",
    "\n",
    "page = httpx.get(generate_url('316', '1', 'sach_truyen_tieng_viet')).json()\n",
    "for i in page['filters']:\n",
    "    if i['display_name'] == 'Danh M·ª•c S·∫£n Ph·∫©m':\n",
    "        categories = i['values']\n",
    "        break\n",
    "\n",
    "print(categories[0])        \n",
    "    \n",
    "all_categories = []\n",
    "for cat in categories:\n",
    "    cat_data = httpx.get(generate_url( cat['query_value'], '1', cat['url_key'] )).json()\n",
    "    has_child = False\n",
    "    for i in cat_data['filters']: \n",
    "        if i['display_name'] == 'Danh M·ª•c S·∫£n Ph·∫©m': # N·∫øu ch·ª©a danh m·ª•c con th√¨ th√™m v√†o\n",
    "            #print(i['display_name'])\n",
    "            all_categories.extend(i['values'])\n",
    "            has_child = True\n",
    "    \n",
    "    if not has_child: \n",
    "        all_categories.append(cat)\n",
    "        \n",
    "print(len(all_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "api limit = 100 -> M·ªói l·∫ßn request l·∫•y ƒë∆∞·ª£c 100 gi√° tr·ªã</br>\n",
    "C·∫ßn l·∫•y gi√° tr·ªã t·ªëi ƒëa c·ªßa s·ªë s√°ch c√≥ th·ªÉ c√≥ trong m·ªôt th·ªÉ lo·∫°i "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L·∫•y id c·ªßa c√°c cu·ªën s√°ch ·ªü t·ª´ng th·ªÉ lo·∫°i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_categories = pd.DataFrame(all_categories)\n",
    "# display(all_categories)\n",
    "id_df = []\n",
    "def get_books_id(cat):\n",
    "    n = (cat['count']//100) + 2\n",
    "    books = {\n",
    "        'categories': cat['display_value'],\n",
    "        'books_id': []\n",
    "    }\n",
    "    for i in range(1, n):\n",
    "        response = httpx.get(generate_url(cat['query_value'], i, cat['url_key'] )).json()\n",
    "        if 'data' in response:\n",
    "            for book in response['data']:\n",
    "                books['books_id'].append({'id': book['id']})\n",
    "                id_df.append({'id': book['id']})\n",
    "    \n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_id_all_cate = []\n",
    "for cate in all_categories:\n",
    "    print(cate['display_value'])\n",
    "    books_id_all_cate.append(get_books_id(cate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_id = pd.DataFrame(books_id_all_cate)\n",
    "categories_id.to_csv('id_data/categories_id.csv', encoding='utf-8-sig')\n",
    "id_df = pd.DataFrame(id_df)\n",
    "with open('id_data/id_df.json', 'w', encoding='utf-8-sig') as file:\n",
    "    id_df.to_json('id_data/id_df.json', force_ascii=False, orient='records')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **L·∫•y th√¥ng tin c·ªßa t·ª´ng cu·ªën s√°ch d·ª±a v√†o id ƒë√£ thu th·∫≠p**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ƒê·ªçc id t·ª´ file id ƒë√£ l·∫•y ƒë∆∞·ª£c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('id_data/id_df.json') as f:\n",
    "        id = json.load(f)\n",
    "except IOError:\n",
    "    print(\"File not found\")\n",
    "    \n",
    "books_id = [i.get('id') for i in id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(books_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi·∫øt c√°c function ƒë·ªÉ l·∫•y d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_book_info(raw_book):\n",
    "    book_info = {\n",
    "                'id': raw_book.get('id'), \n",
    "                'master_id': raw_book.get('master_id'),\n",
    "                'sku': raw_book.get('sku'),\n",
    "                'name': raw_book.get('name'),\n",
    "                'short_url': raw_book.get('short_url'),\n",
    "                #'short_description': raw_book.get('short_description'),\n",
    "                'book_cover': raw_book.get('book_cover'),\n",
    "                'price': raw_book.get('price'),\n",
    "                'original_price': raw_book.get('original_price'),\n",
    "                'discount_rate': raw_book.get('discount_rate'),\n",
    "                'rating_average': raw_book.get('rating_average'),\n",
    "                'review_count': raw_book.get('review_count'),\n",
    "                'inventory_type': raw_book.get('inventory_type'),\n",
    "                'productset_group_name': raw_book.get('productset_group_name'),\n",
    "                'day_ago_created': raw_book.get('day_ago_created'),\n",
    "                'categories': raw_book.get('categories').get('name') if raw_book.get('categories') not in [None,[]] else None,\n",
    "                'all_time_quantity_sold': raw_book.get('all_time_quantity_sold', 0)\n",
    "                }\n",
    "    \n",
    "    # authors_name = []\n",
    "    # authors_name = []\n",
    "    if raw_book.get('authors') not in [None, []] :\n",
    "        authors_name = [i.get('name') for i in raw_book.get('authors')]\n",
    "        book_info['authors'] = ', '.join(authors_name)\n",
    "    else: book_info['authors'] = ''\n",
    "\n",
    "    if raw_book.get('specifications') not in [None, []]:\n",
    "        # print(raw_book['specifications']==[])\n",
    "        for i in raw_book['specifications'][0]['attributes']:\n",
    "            # print(i)\n",
    "            book_info[i['code']] = i['value']\n",
    "    return book_info\n",
    "\n",
    "def split_books_id(books_id: list, i, n): # Part 0: i = 0\n",
    "    length_path = len(books_id)//n\n",
    "    start = length_path*i\n",
    "    end = length_path+length_path*i\n",
    "    if i == n - 1:\n",
    "        end = len(books_id)\n",
    "    return start, end\n",
    "\n",
    "def get_all_books(book_df, start, end):\n",
    "    for id in books_id[start:end]:\n",
    "        url = f'https://tiki.vn/api/v2/products/{id}'\n",
    "        try:\n",
    "            response = httpx.get(url)\n",
    "            raw_book = response.json()\n",
    "            print(response.status_code)\n",
    "            if response.status_code == 200:\n",
    "                book_info = get_book_info(raw_book)\n",
    "                book_df.append(book_info)              \n",
    "        except:\n",
    "            book_df.append(get_book_info(raw_book))\n",
    "            print(f'ERROR:', id)\n",
    "    return book_df\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V√¨ l∆∞·ª£ng d·ªØ li·ªáu kh√° l·ªõn v√† kh√≥ x·ª≠ l√Ω n√™n ta s·∫Ω chia th√†nh c√°c ph·∫ßn nh·ªè sau ƒë√≥ concat l·∫°i:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start, end = split_books_id(books_id, i=0, n=5)\n",
    "# book_df1 = get_all_books(book_df, start, end)\n",
    "# df1 = pd.DataFrame(book_df1)\n",
    "# df1.to_csv('full_data/part_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu√™n encoding :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('full_data/part_1.csv', encoding='utf-8')\n",
    "df.to_csv('full_data/part_1.csv', encoding='utf-8-sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ti·∫øp t·ª•c v·ªõi part 2, 3, .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = []\n",
    "for i in range(1, 5):\n",
    "    book_df = []\n",
    "    start, end = split_books_id(books_id, i, n=5)\n",
    "    book_df = get_all_books(book_df, start, end)\n",
    "    df = pd.DataFrame(book_df)\n",
    "    df.to_csv(f'full_data/part_{i+1}.csv', encoding='utf-8-sig')\n",
    "    all_df.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M·ªói part m·∫•t kho·∫£ng 150 ph√∫t üòÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat c√°c file l·∫°i th√¥i**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.concat(map(pd.read_csv, glob.glob('full_data/*.csv')))\n",
    "df.to_csv('full_data/data.csv', index=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Th·ª≠ l·∫°i v·ªõi multithread**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "import time\n",
    "\n",
    "NUMBER_OF_WORKERS = 4\n",
    "        \n",
    "def handle_get_book_info(book):\n",
    "    url = f'https://tiki.vn/api/v2/products/{book[\"id\"]}'\n",
    "    try:    \n",
    "        response = httpx.get(url)   \n",
    "        print(response.status_code)\n",
    "        if response.status_code == 200: #and 'content-type' in response.headers \n",
    "            #and 'application/json' in response.headers['content-type']):\n",
    "            raw_book = response.json()\n",
    "            \n",
    "            book_info = get_book_info(raw_book, book)\n",
    "            return book_info\n",
    "        # response.raise_for_status()\n",
    "        \n",
    "    except Exception as e:\n",
    "        # df.append(book)\n",
    "        # book_info = response.json()\n",
    "        # if response.status_code == 429:\n",
    "        #     time.sleep(int(response.headers[\"Retry-After\"]))\n",
    "        print(f'ERROR {str(e)}: ', book['id'])\n",
    "        # elif response.status_code == 200:\n",
    "        #     book_info = get_book_info(response.json(), book)\n",
    "        # book_info = raw_book\n",
    "        # return book_info\n",
    "        # return response.json()\n",
    "    # return book_info\n",
    "        \n",
    "test_df = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=NUMBER_OF_WORKERS) as executor:\n",
    "    all_params = list(book for cate in books_id_all_cate[:1] \n",
    "                      for book in cate['Book_id'] )\n",
    "    for future in concurrent.futures.as_completed(\n",
    "        executor.submit(handle_get_book_info, params)\n",
    "        for params in all_params\n",
    "    ):\n",
    "        # result = future.result()\n",
    "        test_df.append(future.result())\n",
    "        #print(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kh√¥ng hi·ªáu qu·∫£ v√¨ t·∫°o ra 429 error -> Too many requests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 16:50:36) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "17b49a1913d9be682908a9e6ac75a9b3bca45cee2e4d43cdb55ba78702e35dcb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
